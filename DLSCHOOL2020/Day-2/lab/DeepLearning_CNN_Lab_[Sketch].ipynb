{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DeepLearning_CNN_Lab [Sketch].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si6cLhP42iU6",
        "colab_type": "text"
      },
      "source": [
        "# Lab 2: Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "916Qmf_V2iVM",
        "colab_type": "text"
      },
      "source": [
        "# 2.1 Dataset pre-processing\n",
        "The first thing that we need to do when we are dealing with a new dataset is to operate some pre-processing operations. Data preprocessing usually refers to the steps applied to make data more suitable for learning. \n",
        "In this section we are going to deal with:\n",
        "* 2.1.1 Dataset loading\n",
        "* 2.1.2 Normalization\n",
        "* 2.1.3 Standardization\n",
        "* 2.1.4 Splitting and label preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKHY2x0z2iVN",
        "colab_type": "text"
      },
      "source": [
        "## 2.1.1 Dataset loading\n",
        "In this section we load the augmented dataset generated in the previous section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnTmYxnF2iVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# Here we are importing the train and test set separated \n",
        "(train_X, train_Y),(test_X, test_Y) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(train_X.shape, test_X.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Soapy9ma2iVU",
        "colab_type": "text"
      },
      "source": [
        "## 2.1.2 Normalization\n",
        "One common practice in training a Neural Network is to normalize the images by dividing each pixel value by the maximum value that we can have, i.e. 255.<br>\n",
        "The purpose of this is to obtain a mean close to 0.<br>\n",
        "Normalizing the data generally speeds up learning and leads to faster convergence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1ar8l3i2iVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# Normalizing the data\n",
        "print(\"Normalizing training set..\")\n",
        "train_X = np.asarray(train_X, dtype=np.float32) / 255\t\t\t\t\t\t\t\t\t\t# Normalizing training set\n",
        "print(\"Normalizing test set..\")\n",
        "test_X = np.asarray(test_X, dtype=np.float32) / 255\t\t\t\t\t\t\t\t\t\t\t# Normalizing test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDvbWAOK2iVX",
        "colab_type": "text"
      },
      "source": [
        "## 2.1.3 Standardization\n",
        "Another common practice in data pre-processing is standardization.<br>\n",
        "The idea about standardization is to compute your dataset mean and standard deviation in order to subtract from every data point $x$ the dataset mean $\\mu$ and then divide by the standard deviation $\\sigma$.<br>\n",
        "That is to apply the following operation:<br>\n",
        "<img src=\"https://drive.google.com/uc?id=1rpuybw_fmI8XK38JQhWWxX2TOExBAV2V\" width=\"150px\"><br>\n",
        "The outcome of this operation is to obtain a distribution with mean equal to 0 and a standard deviation equal to 1.<br>\n",
        "By applying normalization to our data we are making the features more similar to each other and this usually makes the learning process easier.<br>\n",
        "To better understand that we can show an example of what happens after a standardization process is applied to a dataset:\n",
        "<img src=\"https://drive.google.com/uc?id=1wtqTW4hz8n8k7b7q0mUSzCc9X0npNUY2\" width=\"500px\" align=\"left\"><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XUXSyyF2iVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardizing the data\n",
        "def compute_mean_and_std(X):\n",
        "\timage_means = []\n",
        "\timage_stds = []\n",
        "\n",
        "\tmean = np.mean(train_X, axis=(0,1,2))\n",
        "\tstd = np.std(train_X, axis=(0,1,2))\n",
        " \n",
        "\treturn [mean, std]\t\t\t\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLXq4tbi2iVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For every image we subtract to it the dataset mean and we divide by the dataset standard deviation\n",
        "\n",
        "dataset_mean, dataset_std = compute_mean_and_std(train_X)\n",
        "print(\"Standardizing training set..\")\n",
        "train_X = (train_X-dataset_mean)/dataset_std\t\t\t\t\t\t\t\t\t\t\t\t# Standardizing the training set\n",
        "print(\"Standardizing test set..\")\n",
        "test_X = (test_X-dataset_mean)/dataset_std\t\t\t\t\t\t\t\t\t\t\t\t# Standardizing the test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDmQz5yE2iVk",
        "colab_type": "text"
      },
      "source": [
        "## 2.1.4 Splitting and label preprocessing\n",
        "Now we just need to split our training set in orer to get the validation set and convert our labels to one-hot representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWSyCDI72iVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Splitting training set to create validation set..\")\n",
        "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=13)\n",
        "print(train_X.shape)\n",
        "# Converting labels to one-hot representation\n",
        "from keras.utils.np_utils import to_categorical\n",
        "train_Y_one_hot = to_categorical(train_Y)\t\t\t\t\t\t# Converting training labels to one-hot representation\n",
        "valid_Y_one_hot = to_categorical(valid_Y)\t\t\t\t\t\t# Converting validation labels to one-hot representation\n",
        "test_Y_one_hot = to_categorical(test_Y)\t\t\t\t\t\t\t# Converting test labels to one-hot representation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLIf2fS62iVn",
        "colab_type": "text"
      },
      "source": [
        "# 2.2 Training a model from scratch\n",
        "Now that we have properly pre-processed our data, we are going to create a convolutional model in Keras. \n",
        "Usually a convolutional model is made by two subsequent part:\n",
        "* A convolutional part\n",
        "* A fully connected\n",
        "\n",
        "We can show an example of the general structure in the next picture:\n",
        "<img src=\"https://drive.google.com/uc?id=1duP8u9bs6ELNu4degUuYP4-YS1mBYn2O\" width=\"600px\"><br>\n",
        "\n",
        "Usually the convolutional part is made by some layers composed by\n",
        "* convolutional layer: performs a spatial convolution over images (see Conv2D)\n",
        "* pooling layer: used to reduce the output spatial dimension from $n$ to 1 by averaging the $n$ different value or considering the maximum between them (see MaxPool2D)\n",
        "* dropout layer: applied to a layer, consists of randomly \"dropping out\" (i.e. set to zero) a number of output features of the layer during training. (see DropOut)\n",
        "\n",
        "The convolutional part produces its output and the fully connected part ties together the received information in order to solve the classification problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SQ6lArz2iVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the model from scratch\n",
        "import keras\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "categories = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "\n",
        "# Network parameters\n",
        "batch_size = 16\t\t\t\t\t\t\t\t\t\t\t\t\t# Setting the batch size\n",
        "epochs = 6\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Setting the number of epochs\n",
        "num_classes = len(categories)\t\t\t\t\t\t\t\t\t# Getting the amount of classes\n",
        "\n",
        "scratch_model = Sequential()\t\n",
        "\n",
        "# Build here your keras model.\n",
        "# Try to use one or more convolutional layer, joint with pooling layer and dropout layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model with the Adam optimizer\n",
        "scratch_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "\n",
        "# Visualize the model through the summary function\n",
        "scratch_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azjgug3Q2iVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's train the model!\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbPMcLKV2iVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the results\n",
        "scratch_model_train_acc = scratch_model_history.history['accuracy']\n",
        "scratch_model_valid_acc = scratch_model_history.history['val_accuracy']\n",
        "scratch_model_train_loss = scratch_model_history.history['loss']\n",
        "scratch_model_valid_loss = scratch_model_history.history['val_loss']\n",
        "\n",
        "print(\"Test accuracy: \", accuracy_score(scratch_model.predict_classes(test_X), test_Y))\t\t\t# Testing the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWiB0JKK2iV1",
        "colab_type": "text"
      },
      "source": [
        "**Is the obtained value coherent with what you expected?**<br>\n",
        "**What are the differences when using a different batch size? Why?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkRwEUtQ2iV1",
        "colab_type": "text"
      },
      "source": [
        "# 2.3 Data Augmentation\n",
        "Before even starting to load the dataset we should ask ourself whether the available amount of data is sufficient to our purposes.<br>\n",
        "When the answer is negative we could need to do \"data augmentation\".<br>\n",
        "Doing data augmentation means to increase the number of available data points. In terms of images, it may mean that increasing the number of images in the dataset. A common way to do this is to generate new images by applying a linear transformation to the original images in the dataset.<br>\n",
        "The most common linear transformations are the following:<br>\n",
        "* Rotation\n",
        "* Shifting\n",
        "* Blurring\n",
        "* Change lighting conditions\n",
        "\n",
        "In the picture below we show an example of augmentation:<br>\n",
        "<img src=\"https://drive.google.com/uc?id=1B74snda_oJKkhVzxch9Ov8Y1XL63U3w5\" width=\"600px\" align=\"left\"><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Kg8HgQ2iV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Augmentation parameters\n",
        "noise_range = 5\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Gaussian blur range\n",
        "flip_hor_prob = 0.5\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Probability to flip horizontally the image\n",
        "rot_range = 30\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Rotation range\n",
        "\n",
        "print(train_X.shape, test_X.shape)\n",
        "\n",
        "#Try different augmentation strategies\n",
        "cifar10_datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    #rotation_range=20,\n",
        "    #width_shift_range=0.1,\n",
        "    #height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9EM9pG2iWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "scratch_model = Sequential()\t\n",
        "\n",
        "# Build here your keras model.\n",
        "# Try to use one or more convolutional layer, joint with pooling layer and dropout layer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train your model\n",
        "\n",
        "\n",
        "\n",
        "# Getting the results\n",
        "scratch_model_train_acc = scratch_model_history.history['accuracy']\n",
        "scratch_model_valid_acc = scratch_model_history.history['val_accuracy']\n",
        "scratch_model_train_loss = scratch_model_history.history['loss']\n",
        "scratch_model_valid_loss = scratch_model_history.history['val_loss']\n",
        "\n",
        "print(\"Test accuracy: \", accuracy_score(scratch_model.predict_classes(test_X), test_Y))\t\t\t# Testing the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEQiqXC42iWP",
        "colab_type": "text"
      },
      "source": [
        "**What is the performance obtained on this new augmented dataset?**<br>\n",
        "**How can you explain the obtained result?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3_XbZQg2iWQ",
        "colab_type": "text"
      },
      "source": [
        "# 2.4 Using a pre-trained model\n",
        "\n",
        "A common alternative to train a model from scratch consists in using a pre-trained model.<br>\n",
        "The idea is to replace the convolutional part with a highly optimized convolutional part engineered and trained previously by someone else.<br>\n",
        "Usually the models that we can use through keras.applications have been trained over the image net dataset. <br>\n",
        "Today we are going to use the VGG19 model. Its architecture it is shown below:\n",
        "<img src=\"https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means_W640.jpg\" width=\"600px\"><br>\n",
        "After the convolutional part replacement we still need to set up a fully connected part.<br>\n",
        "**Why in this lab we cannot use the fully connected part of VGG19 Net?<br>\n",
        "What should we do to use it?<br>\n",
        "And more in general in which situations we can do that?**\n",
        "\n",
        "Moreover, using a pre-trained network is not always the best choice<br>\n",
        "**Can you guess in which situations could be useful to use a pre-trained model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8dz23k2iWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the model based over the pretrained Xception network\n",
        "from keras import applications\n",
        "vgg19 = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (32, 32, 3))\n",
        "\n",
        "# Produce the features of the train and validation sets using VGG19 predict function\n",
        "\n",
        "\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "# Creating a simple model that will classify the extracted features from the VGG19 network\n",
        "pretrained_model = models.Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyHEx6bS2iWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the model through the summary function\n",
        "vgg19.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Dkp9ix2iWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's train the model!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJaZdXQT2iWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the results\n",
        "pretrained_model_train_acc = pretrained_model_history.history['acc']\n",
        "pretrained_model_valid_acc = pretrained_model_history.history['val_acc']\n",
        "pretrained_model_train_loss = pretrained_model_history.history['loss']\n",
        "pretrained_model_valid_loss = pretrained_model_history.history['val_loss']\n",
        "\n",
        "test_X_feature = vgg19.predict(test_X)\t\t\t\t\t\t# Producing the test feature\n",
        "print(\"Test accuracy: \", accuracy_score(pretrained_model.predict_classes(test_X_feature), test_Y)) # Testing the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_2_LXsy2iWg",
        "colab_type": "text"
      },
      "source": [
        "# 2.5 Comparing the models\n",
        "\n",
        "\n",
        "Now that we trained both the \"from scratch\" and the \"pre-trained\" models, we are going to compare the obtained results obtained during the training. We are going to consider accuracy and loss.<br>\n",
        "**What can you expect from these plots?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vovtvdUg2iWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create here the plots to compare the \"from scratch\" model and the \"pretrained\" model\n",
        "# Try to produce a comparison plot about the accuracies (train and validation) and another plot for the losses\n",
        "# Creating the plots to compare the \"from scratch\" model and the \"pretrained\" model\n",
        "# Producing accuracy over epochs plot\n",
        "print(\"Producing accuracy over epochs plot\")\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(16,7))\n",
        "\n",
        "plt.plot(scratch_model_train_acc, label=\"Scratch Train Acc.\", color=\"#4db8ff\")\n",
        "plt.plot(scratch_model_valid_acc, label=\"Scratch Valid. Acc.\", color=\"#006bb3\")\n",
        "\n",
        "plt.plot(pretrained_model_train_acc, label=\"Pretrained Train Acc.\", color=\"#ff4d4d\")\n",
        "plt.plot(pretrained_model_valid_acc, label=\"Pretrained Valid. Acc.\", color=\"#b30000\")\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy(%)')\n",
        "plt.legend(loc='lower right', fancybox=True, shadow=True, ncol=4)\n",
        "plt.grid()\n",
        "plt.savefig('acc_epochs.png', dpi=300)\n",
        "\n",
        "\n",
        "# Producing loss over epochs plot\n",
        "print(\"Producing loss over epochs plot\")\n",
        "fig = plt.figure(figsize=(16,7))\n",
        "\n",
        "plt.plot(scratch_model_train_loss, label=\"Scratch Train Loss\", color=\"#4db8ff\")\n",
        "plt.plot(scratch_model_valid_loss, label=\"Scratch Valid. Loss\", color=\"#006bb3\")\n",
        "\n",
        "plt.plot(pretrained_model_train_loss, label=\"Pretrained Train Loss\", color=\"#ff4d4d\")\n",
        "plt.plot(pretrained_model_valid_loss, label=\"Pretrained Valid. Loss\", color=\"#b30000\")\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right', fancybox=True, shadow=True, ncol=4)\n",
        "plt.grid()\n",
        "plt.savefig('loss_epochs.png', dpi=300)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bszQNCEz2iWq",
        "colab_type": "text"
      },
      "source": [
        "**What information can you get from these plots?**<br>\n",
        "**Are they showing what you expected?**"
      ]
    }
  ]
}